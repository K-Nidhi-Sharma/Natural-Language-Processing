{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b936bb59",
   "metadata": {},
   "source": [
    "# <center> NATURAL LANGUAGE PROCESSING (NLP) </center>\n",
    "### <center> K NIDHI SHARMA, 2148041 </center>\n",
    "### <center> Calculating similarity between two sentences using wordnet </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b4f0f",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb14461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86530d64",
   "metadata": {},
   "source": [
    "Declaring sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62cf349",
   "metadata": {},
   "source": [
    "sen1=\"Department of Data Science and Statistics had organized a four-day workshop on Developing Data Science Projects.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90af8e0",
   "metadata": {},
   "source": [
    "sen2=\"A four-day workshop on Developing Data Science Projects has been organized by the Department of Data Science and Statistics.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a34d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter Today is raining \n",
      "enter It is raining today\n"
     ]
    }
   ],
   "source": [
    "sen1=input(\"enter \")\n",
    "sen2=input(\"enter \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94777d",
   "metadata": {},
   "source": [
    "Tokenizing the sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb8d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today', 'is', 'raining']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words1=word_tokenize(sen1)\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cae95e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'is', 'raining', 'today']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2=word_tokenize(sen2)\n",
    "words2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d9255",
   "metadata": {},
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20e7524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['today', 'raining']\n"
     ]
    }
   ],
   "source": [
    "#stop words in nltk library\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#removing stop words from the tokenized list\n",
    "tokens_1 = word_tokenize(sen1)\n",
    "cleantoken_1=[]\n",
    "\n",
    "for w in tokens_1:\n",
    "    if(w.lower() not in stop_words):\n",
    "        cleantoken_1.append(w.lower())\n",
    "print(cleantoken_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecd2883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raining', 'today']\n"
     ]
    }
   ],
   "source": [
    "#stop words in nltk library\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#removing stop words from the tokenized list\n",
    "tokens_2 = word_tokenize(sen2)\n",
    "cleantoken_2=[]\n",
    "\n",
    "for w in tokens_2:\n",
    "    if(w.lower() not in stop_words):\n",
    "        cleantoken_2.append(w.lower())\n",
    "print(cleantoken_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a7ed5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('today.n.01'),\n",
       "  Synset('today.n.02'),\n",
       "  Synset('nowadays.r.01'),\n",
       "  Synset('today.r.02')],\n",
       " [Synset('rain.v.01'), Synset('raining.s.01')]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn1=[]\n",
    "for i in cleantoken_1:\n",
    "    syn1.append(wn.synsets(i))\n",
    "syn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08982f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('today.n.01'), Synset('rain.v.01')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1=[]\n",
    "for i in range(len(syn1)):\n",
    "    if(len(syn1[i])>0):\n",
    "        s1.append(syn1[i][0])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e7a547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('rain.v.01'), Synset('raining.s.01')],\n",
       " [Synset('today.n.01'),\n",
       "  Synset('today.n.02'),\n",
       "  Synset('nowadays.r.01'),\n",
       "  Synset('today.r.02')]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn2=[]\n",
    "for i in cleantoken_2:\n",
    "    syn2.append(wn.synsets(i))\n",
    "\n",
    "syn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03941b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('rain.v.01'), Synset('today.n.01')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2=[]\n",
    "for i in range(len(syn2)):\n",
    "    if(len(syn2[i])>0):\n",
    "        s2.append(syn2[i][0])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d243b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 1.0, 1.0, 0.2]\n"
     ]
    }
   ],
   "source": [
    "score=[]\n",
    "for i in range(len(s1)):\n",
    "    for j in range(len(s2)):\n",
    "        score.append(s1[i].wup_similarity(s2[j]))\n",
    "print(score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90786419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e31cf2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Similarity Score = 60.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage Similarity Score = {statistics.mean(score):.2%}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
